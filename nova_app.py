import streamlit as st
import openai
import os
from dotenv import load_dotenv
from audiorecorder import audiorecorder
from pydub import AudioSegment
import base64
import tempfile

# Load the .env file (API keys)
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# Set page config
st.set_page_config(
    page_title="Nova Audio FAQ Assistant ü§ñüéß",
    layout="centered",
    page_icon="üéôÔ∏è",
    initial_sidebar_state="expanded"
)

# Sidebar
with st.sidebar:
    st.image("nova_bot.png", width=200)
    st.markdown("## üëã Welcome to Nova!")
    st.markdown("Ask your college FAQs via voice.")
    st.markdown("#### üí° Tip: Speak clearly into your mic.")
    st.markdown("---")
    st.markdown("Made with ‚ù§Ô∏è by Team Nova")

st.title("üéß Ask Nova: Your FAQ Audio Assistant")

# Audio recording
audio = audiorecorder("üé§ Record", "üî¥ Stop")

if len(audio) > 0:
    with st.spinner("Transcribing your question..."):
        # Save to temp WAV file
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
            audio.export(f.name, format="wav")
            temp_path = f.name

        # Send to OpenAI Whisper
        audio_file = open(temp_path, "rb")
        transcript = openai.Audio.transcribe("whisper-1", audio_file)

        st.success("‚úÖ Transcription Complete!")
        st.markdown(f"**üìù You asked:** `{transcript['text']}`")

        # Send to GPT
        with st.spinner("Fetching Nova's answer..."):
            completion = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "You're Nova, a helpful assistant answering college FAQ questions."},
                    {"role": "user", "content": transcript["text"]}
                ]
            )
            answer = completion.choices[0].message["content"]
            st.markdown("### üß† Nova says:")
            st.success(answer)
